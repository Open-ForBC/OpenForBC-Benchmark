<?xml version="1.0"?>
<!--Phoronix Test Suite v9.0.0-->
<PhoronixTestSuite>
  <TestInformation>
    <Title>MKL-DNN DNNL</Title>
    <AppVersion>1.1</AppVersion>
    <Description>This is a test of the Intel MKL-DNN (DNNL / Deep Neural Network Library) as an Intel-optimized library for Deep Neural Networks and making use of its built-in benchdnn functionality. The result is the total perf time reported.</Description>
    <ResultScale>ms</ResultScale>
    <Proportion>LIB</Proportion>
    <TimesToRun>3</TimesToRun>
  </TestInformation>
  <TestProfile>
    <Version>1.1.1</Version>
    <SupportedPlatforms>Linux</SupportedPlatforms>
    <SoftwareType>Utility</SoftwareType>
    <TestType>Processor</TestType>
    <License>Free</License>
    <Status>Verified</Status>
    <ExternalDependencies>build-utilities, cmake</ExternalDependencies>
    <EnvironmentSize>355</EnvironmentSize>
    <ProjectURL>https://github.com/intel/mkl-dnn</ProjectURL>
    <InternalTags>SMP, OpenMP</InternalTags>
    <Maintainer>Michael Larabel</Maintainer>
  </TestProfile>
  <TestSettings>
    <Option>
      <DisplayName>Harness</DisplayName>
      <Identifier>harness</Identifier>
      <Menu>
        <Entry>
          <Name>Convolution Batch conv_all</Name>
          <Value>--conv --batch=inputs/conv/conv_all</Value>
        </Entry>
        <Entry>
          <Name>Convolution Batch conv_3d</Name>
          <Value>--conv --batch=inputs/conv/conv_3d</Value>
        </Entry>
        <Entry>
          <Name>Convolution Batch conv_alexnet</Name>
          <Value>--conv --batch=inputs/conv/conv_alexnet</Value>
        </Entry>
        <Entry>
          <Name>Convolution Batch conv_googlenet_v3</Name>
          <Value>--conv --batch=inputs/conv/conv_googlenet_v3</Value>
        </Entry>
        <Entry>
          <Name>Deconvolution Batch deconv_all</Name>
          <Value>--deconv --batch=inputs/deconv/deconv_all</Value>
        </Entry>
        <Entry>
          <Name>Deconvolution Batch deconv_1d</Name>
          <Value>--deconv --batch=inputs/deconv/deconv_1d</Value>
        </Entry>
        <Entry>
          <Name>Deconvolution Batch deconv_3d</Name>
          <Value>--deconv --batch=inputs/deconv/deconv_3d</Value>
        </Entry>
        <Entry>
          <Name>IP Batch 1D</Name>
          <Value>--ip --batch=inputs/ip/ip_1d</Value>
        </Entry>
        <Entry>
          <Name>IP Batch All</Name>
          <Value>--ip --batch=inputs/ip/ip_all</Value>
        </Entry>
        <Entry>
          <Name>Recurrent Neural Network Training</Name>
          <Value>--rnn --batch=inputs/rnn/rnn_training</Value>
        </Entry>
      </Menu>
    </Option>
    <Option>
      <DisplayName>Data Type</DisplayName>
      <Identifier>data-type</Identifier>
      <ArgumentPrefix>--cfg=</ArgumentPrefix>
      <Menu>
        <Entry>
          <Name>f32</Name>
          <Value>f32</Value>
        </Entry>
        <Entry>
          <Name>u8s8f32</Name>
          <Value>u8s8f32</Value>
          <Message>Optimized For AVX-512</Message>
        </Entry>
        <Entry>
          <Name>bf16bf16bf16</Name>
          <Value>bf16bf16bf16</Value>
          <Message>Optimized For AVX-512 + VNNI</Message>
        </Entry>
      </Menu>
    </Option>
  </TestSettings>
</PhoronixTestSuite>
