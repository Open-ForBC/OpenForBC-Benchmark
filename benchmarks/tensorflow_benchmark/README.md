# OpenForBC Tensorflow benchmark

## Description

This benchmark is a collection of machine learning benchmarks all based on
Tensorflow.

Every benchmark measures the average time per sample for each operation mode.

Benchmarks can run in either training or inference mode: there are multiple
presets for each benchmark.

## Requirements

Tensorflow requires NVIDIA CUDNN and some CUDA libraries to run, specifically:

- `cudart`
- `libcublas`
- `libcufft`
- `libcurand`
- `libcusolver`
- `libcusparse`
  
## Benchmark list

### CIFAR10 Deep Learning benchmark

This benchmark implements a convolutional neural network and performs training
and inference over the CIFAR10 dataset.

CIFAR10 is a well known image recognition dataset suitable for benchmarking
application due to its simple structure and low complexity. The CNN implemented
by the benchmark has two convolutional layers and one fully connected layer.

### MNIST Deep Learning benchmark

This benchmark implements a fully connected neural network and performs training
and inference over the MNIST dataset.

MNIST is a well known image recognition dataset suitable for benchmarking
application due to its simple structure and low complexity. The FCNN implemented
by the benchamrk has three fully connected layers.

### TCGA topicmodeling benchmark

Run a benchmark on The Cancer Genome Atlas data. The original 20000 dimensional
space is firstly reduced with topic modeling tecniques described in [A Topic
Modeling Analysis of TCGA Breast and Lung Cancer Transcriptomic
Data](https://doi.org/10.3390/cancers12123799) the a NN predictor is trained in
a lower dimensional (explainable and biologically relevant) space.

##### License

The results shown here are in part based upon data generated by the TCGA
Research Network: [https://www.cancer.gov/tcga](https://www.cancer.gov/tcga).

### TeacherStudent realtime benchmark

This benchmark implements a neural network of customizible dimension and
performs training and inference over an artificial dataset. Teacher-student
refers to a learning technique in which a "student" model has to learn a dataset
of input-output where the output distribution function is defined by a "teacher"
network.

The FCNN implemented by the benchmark has by default one hidden layer, but the
architecture can be set from a few parameters inside the code.